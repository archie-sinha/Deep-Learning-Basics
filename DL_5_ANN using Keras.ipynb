{"cells":[{"cell_type":"markdown","metadata":{"id":"ZTNrZjq54KOV"},"source":["#**Archisha Sinha**\n","##Course: Deep Learning\n","##Title: ANN using Keras with Fashionmnist Dataset\n"]},{"cell_type":"markdown","source":["# Importing Libraries"],"metadata":{"id":"sUJPnyQkZJxL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BgAR9SPdFP78"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import tensorflow as tf\n","import keras\n","from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ce0833qIWnZU"},"outputs":[],"source":["(X_train, Y_train), (X_test, Y_test)= tf.keras.datasets.fashion_mnist.load_data()"]},{"cell_type":"markdown","metadata":{"id":"qYnDTV92X0mU"},"source":["## Pre-Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1698144567907,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"Srw2oi03W5SF","outputId":"647d4681-98d1-4caa-84fb-a381750c205f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 28, 28)"]},"metadata":{},"execution_count":129}],"source":["X_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4vyuSNFKW9Bb"},"outputs":[],"source":["img_rows, img_col= 28,28"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tj5metBAXCMz"},"outputs":[],"source":["X_train_mlp= X_train.reshape(X_train.shape[0], img_rows*img_col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"peFx1lKcebXS"},"outputs":[],"source":["Y_train_mlp=Y_train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KQR6MWPrctMJ"},"outputs":[],"source":["\n","X_test_mlp= X_test.reshape(X_test.shape[0], img_rows*img_col)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vj0sUmoaXW9d"},"outputs":[],"source":["Y_test_mlp=Y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1698144567908,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"yGefkHVnX89o","outputId":"1e8b3121-d68b-462d-ca4d-661b01e8f65f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 784)"]},"metadata":{},"execution_count":135}],"source":["X_train_mlp.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1698144567908,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"aBLpL-BmYA3I","outputId":"d6bf0e8d-b95d-4b56-a491-0b171db59dd2"},"outputs":[{"output_type":"stream","name":"stdout","text":["X_train shape:  (60000, 28, 28)\n","Y_train shape:  (60000,)\n"]}],"source":["print(\"X_train shape: \", X_train.shape)\n","print(\"Y_train shape: \", Y_train.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L-zHtGfAY3ph"},"outputs":[],"source":["#Define labels\n","fashion_mnist_labels=[\"T-shirt/top\", #index 0\n","                     \"Trousser\",  #index 1\n","                     \"Pullover\",  #index 2\n","                     \"Dress\",  #index 3\n","                     \"Coat\",  #index 4\n","                     \"Sandal\",  #index 5\n","                     \"Shirt\",  #index 6\n","                     \"Sneaker\",  #index 7\n","                     \"Bag\",  #index 8\n","                     \"Ankle boot\"]  #index 9"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBe1s1HJagdT"},"outputs":[],"source":["#Image Index we can pickup any number between 0 and 59,999\n","img_index=5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yUaVMiW_a1jn"},"outputs":[],"source":["label_index= Y_train[img_index]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1698144567908,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"QWmrHvUAa9qP","outputId":"e033e5cb-152c-43cb-b590-0a1634762481"},"outputs":[{"output_type":"stream","name":"stdout","text":["Y=2 Pullover\n"]}],"source":["print(\"Y=\"+ str(label_index)+ \" \"+ (fashion_mnist_labels[label_index]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1698144567908,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"iP0SG-axbrfv","outputId":"8480ab94-5ff8-4cdb-c5a6-a16582588056"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x79593d34d1e0>"]},"metadata":{},"execution_count":141},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["plt.imshow(X_train[img_index])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1698144567908,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"j40dbjgEb7Se","outputId":"05f1713b-25a8-47c3-df0f-cbaa5e60d3be"},"outputs":[{"output_type":"stream","name":"stdout","text":["(60000, 784)\n"]}],"source":["print(X_train_mlp.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1698144567908,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"mcDs1j5_cG8F","outputId":"6de24e74-a67c-45a8-cb01-1a9df56d73a3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   1,   0,   0,  13,  73,   0,   0,   1,\n","         4,   0,   0,   0,   0,   1,   1,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   3,   0,  36, 136, 127,  62,\n","        54,   0,   0,   0,   1,   3,   4,   0,   0,   3,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0, 102, 204,\n","       176, 134, 144, 123,  23,   0,   0,   0,   0,  12,  10,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","       155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,  72,\n","        15,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n","         0,  69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,\n","        88, 172,  66,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n","         1,   1,   0, 200, 232, 232, 233, 229, 223, 223, 215, 213, 164,\n","       127, 123, 196, 229,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0, 183, 225, 216, 223, 228, 235, 227, 224,\n","       222, 224, 221, 223, 245, 173,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0, 193, 228, 218, 213, 198, 180,\n","       212, 210, 211, 213, 223, 220, 243, 202,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   1,   3,   0,  12, 219, 220, 212, 218,\n","       192, 169, 227, 208, 218, 224, 212, 226, 197, 209,  52,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99, 244, 222,\n","       220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119, 167,  56,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n","       236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n","        92,   0,   0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,\n","         0, 237, 226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215,\n","       218, 255,  77,   0,   0,   3,   0,   0,   0,   0,   0,   0,   0,\n","        62, 145, 204, 228, 207, 213, 221, 218, 208, 211, 218, 224, 223,\n","       219, 215, 224, 244, 159,   0,   0,   0,   0,   0,  18,  44,  82,\n","       107, 189, 228, 220, 222, 217, 226, 200, 205, 211, 230, 224, 234,\n","       176, 188, 250, 248, 233, 238, 215,   0,   0,  57, 187, 208, 224,\n","       221, 224, 208, 204, 214, 208, 209, 200, 159, 245, 193, 206, 223,\n","       255, 255, 221, 234, 221, 211, 220, 232, 246,   0,   3, 202, 228,\n","       224, 221, 211, 211, 214, 205, 205, 205, 220, 240,  80, 150, 255,\n","       229, 221, 188, 154, 191, 210, 204, 209, 222, 228, 225,   0,  98,\n","       233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217, 241,\n","        65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224, 229,\n","        29,  75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206,\n","       198, 213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220,\n","       221, 230,  67,  48, 203, 183, 194, 213, 197, 185, 190, 194, 192,\n","       202, 214, 219, 221, 220, 236, 225, 216, 199, 206, 186, 181, 177,\n","       172, 181, 205, 206, 115,   0, 122, 219, 193, 179, 171, 183, 196,\n","       204, 210, 213, 207, 211, 210, 200, 196, 194, 191, 195, 191, 198,\n","       192, 176, 156, 167, 177, 210,  92,   0,   0,  74, 189, 212, 191,\n","       175, 172, 175, 181, 185, 188, 189, 188, 193, 198, 204, 209, 210,\n","       210, 211, 188, 188, 194, 192, 216, 170,   0,   2,   0,   0,   0,\n","        66, 200, 222, 237, 239, 242, 246, 243, 244, 221, 220, 193, 191,\n","       179, 182, 182, 181, 176, 166, 168,  99,  58,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         0,   0,   0,   0], dtype=uint8)"]},"metadata":{},"execution_count":143}],"source":["X_train_mlp[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IcdT-K1ucKk-"},"outputs":[],"source":["X_train_mlp= X_train_mlp.astype(\"float32\")\n","X_test_mlp= X_test_mlp.astype(\"float32\")\n","X_train_mlp/=255\n","X_test_mlp/=255"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1698144568371,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"yLRQrntbclcF","outputId":"88e51151-6e71-46c2-ad02-0fccb50a5942"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.00392157, 0.        , 0.        , 0.05098039,\n","       0.28627452, 0.        , 0.        , 0.00392157, 0.01568628,\n","       0.        , 0.        , 0.        , 0.        , 0.00392157,\n","       0.00392157, 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.01176471,\n","       0.        , 0.14117648, 0.53333336, 0.49803922, 0.24313726,\n","       0.21176471, 0.        , 0.        , 0.        , 0.00392157,\n","       0.01176471, 0.01568628, 0.        , 0.        , 0.01176471,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n","       0.8       , 0.6901961 , 0.5254902 , 0.5647059 , 0.48235294,\n","       0.09019608, 0.        , 0.        , 0.        , 0.        ,\n","       0.04705882, 0.03921569, 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.60784316, 0.9254902 , 0.8117647 ,\n","       0.69803923, 0.41960785, 0.6117647 , 0.6313726 , 0.42745098,\n","       0.2509804 , 0.09019608, 0.3019608 , 0.50980395, 0.28235295,\n","       0.05882353, 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.00392157, 0.        , 0.27058825,\n","       0.8117647 , 0.8745098 , 0.85490197, 0.84705883, 0.84705883,\n","       0.6392157 , 0.49803922, 0.4745098 , 0.47843137, 0.57254905,\n","       0.5529412 , 0.34509805, 0.6745098 , 0.25882354, 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.00392157, 0.00392157,\n","       0.00392157, 0.        , 0.78431374, 0.9098039 , 0.9098039 ,\n","       0.9137255 , 0.8980392 , 0.8745098 , 0.8745098 , 0.84313726,\n","       0.8352941 , 0.6431373 , 0.49803922, 0.48235294, 0.76862746,\n","       0.8980392 , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.7176471 , 0.88235295, 0.84705883, 0.8745098 , 0.89411765,\n","       0.92156863, 0.8901961 , 0.8784314 , 0.87058824, 0.8784314 ,\n","       0.8666667 , 0.8745098 , 0.9607843 , 0.6784314 , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.75686276, 0.89411765,\n","       0.85490197, 0.8352941 , 0.7764706 , 0.7058824 , 0.83137256,\n","       0.8235294 , 0.827451  , 0.8352941 , 0.8745098 , 0.8627451 ,\n","       0.9529412 , 0.7921569 , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.00392157, 0.01176471, 0.        ,\n","       0.04705882, 0.85882354, 0.8627451 , 0.83137256, 0.85490197,\n","       0.7529412 , 0.6627451 , 0.8901961 , 0.8156863 , 0.85490197,\n","       0.8784314 , 0.83137256, 0.8862745 , 0.77254903, 0.81960785,\n","       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.02352941, 0.        , 0.3882353 , 0.95686275,\n","       0.87058824, 0.8627451 , 0.85490197, 0.79607844, 0.7764706 ,\n","       0.8666667 , 0.84313726, 0.8352941 , 0.87058824, 0.8627451 ,\n","       0.9607843 , 0.46666667, 0.654902  , 0.21960784, 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.01568628, 0.        ,\n","       0.        , 0.21568628, 0.9254902 , 0.89411765, 0.9019608 ,\n","       0.89411765, 0.9411765 , 0.9098039 , 0.8352941 , 0.85490197,\n","       0.8745098 , 0.91764706, 0.8509804 , 0.8509804 , 0.81960785,\n","       0.36078432, 0.        , 0.        , 0.        , 0.00392157,\n","       0.01568628, 0.02352941, 0.02745098, 0.00784314, 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.92941177,\n","       0.8862745 , 0.8509804 , 0.8745098 , 0.87058824, 0.85882354,\n","       0.87058824, 0.8666667 , 0.84705883, 0.8745098 , 0.8980392 ,\n","       0.84313726, 0.85490197, 1.        , 0.3019608 , 0.        ,\n","       0.        , 0.01176471, 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.24313726,\n","       0.5686275 , 0.8       , 0.89411765, 0.8117647 , 0.8352941 ,\n","       0.8666667 , 0.85490197, 0.8156863 , 0.827451  , 0.85490197,\n","       0.8784314 , 0.8745098 , 0.85882354, 0.84313726, 0.8784314 ,\n","       0.95686275, 0.62352943, 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.07058824, 0.17254902, 0.32156864,\n","       0.41960785, 0.7411765 , 0.89411765, 0.8627451 , 0.87058824,\n","       0.8509804 , 0.8862745 , 0.78431374, 0.8039216 , 0.827451  ,\n","       0.9019608 , 0.8784314 , 0.91764706, 0.6901961 , 0.7372549 ,\n","       0.98039216, 0.972549  , 0.9137255 , 0.93333334, 0.84313726,\n","       0.        , 0.        , 0.22352941, 0.73333335, 0.8156863 ,\n","       0.8784314 , 0.8666667 , 0.8784314 , 0.8156863 , 0.8       ,\n","       0.8392157 , 0.8156863 , 0.81960785, 0.78431374, 0.62352943,\n","       0.9607843 , 0.75686276, 0.80784315, 0.8745098 , 1.        ,\n","       1.        , 0.8666667 , 0.91764706, 0.8666667 , 0.827451  ,\n","       0.8627451 , 0.9098039 , 0.9647059 , 0.        , 0.01176471,\n","       0.7921569 , 0.89411765, 0.8784314 , 0.8666667 , 0.827451  ,\n","       0.827451  , 0.8392157 , 0.8039216 , 0.8039216 , 0.8039216 ,\n","       0.8627451 , 0.9411765 , 0.3137255 , 0.5882353 , 1.        ,\n","       0.8980392 , 0.8666667 , 0.7372549 , 0.6039216 , 0.7490196 ,\n","       0.8235294 , 0.8       , 0.81960785, 0.87058824, 0.89411765,\n","       0.88235295, 0.        , 0.38431373, 0.9137255 , 0.7764706 ,\n","       0.8235294 , 0.87058824, 0.8980392 , 0.8980392 , 0.91764706,\n","       0.9764706 , 0.8627451 , 0.7607843 , 0.84313726, 0.8509804 ,\n","       0.94509804, 0.25490198, 0.28627452, 0.41568628, 0.45882353,\n","       0.65882355, 0.85882354, 0.8666667 , 0.84313726, 0.8509804 ,\n","       0.8745098 , 0.8745098 , 0.8784314 , 0.8980392 , 0.11372549,\n","       0.29411766, 0.8       , 0.83137256, 0.8       , 0.75686276,\n","       0.8039216 , 0.827451  , 0.88235295, 0.84705883, 0.7254902 ,\n","       0.77254903, 0.80784315, 0.7764706 , 0.8352941 , 0.9411765 ,\n","       0.7647059 , 0.8901961 , 0.9607843 , 0.9372549 , 0.8745098 ,\n","       0.85490197, 0.83137256, 0.81960785, 0.87058824, 0.8627451 ,\n","       0.8666667 , 0.9019608 , 0.2627451 , 0.1882353 , 0.79607844,\n","       0.7176471 , 0.7607843 , 0.8352941 , 0.77254903, 0.7254902 ,\n","       0.74509805, 0.7607843 , 0.7529412 , 0.7921569 , 0.8392157 ,\n","       0.85882354, 0.8666667 , 0.8627451 , 0.9254902 , 0.88235295,\n","       0.84705883, 0.78039217, 0.80784315, 0.7294118 , 0.70980394,\n","       0.69411767, 0.6745098 , 0.70980394, 0.8039216 , 0.80784315,\n","       0.4509804 , 0.        , 0.47843137, 0.85882354, 0.75686276,\n","       0.7019608 , 0.67058825, 0.7176471 , 0.76862746, 0.8       ,\n","       0.8235294 , 0.8352941 , 0.8117647 , 0.827451  , 0.8235294 ,\n","       0.78431374, 0.76862746, 0.7607843 , 0.7490196 , 0.7647059 ,\n","       0.7490196 , 0.7764706 , 0.7529412 , 0.6901961 , 0.6117647 ,\n","       0.654902  , 0.69411767, 0.8235294 , 0.36078432, 0.        ,\n","       0.        , 0.2901961 , 0.7411765 , 0.83137256, 0.7490196 ,\n","       0.6862745 , 0.6745098 , 0.6862745 , 0.70980394, 0.7254902 ,\n","       0.7372549 , 0.7411765 , 0.7372549 , 0.75686276, 0.7764706 ,\n","       0.8       , 0.81960785, 0.8235294 , 0.8235294 , 0.827451  ,\n","       0.7372549 , 0.7372549 , 0.7607843 , 0.7529412 , 0.84705883,\n","       0.6666667 , 0.        , 0.00784314, 0.        , 0.        ,\n","       0.        , 0.25882354, 0.78431374, 0.87058824, 0.92941177,\n","       0.9372549 , 0.9490196 , 0.9647059 , 0.9529412 , 0.95686275,\n","       0.8666667 , 0.8627451 , 0.75686276, 0.7490196 , 0.7019608 ,\n","       0.7137255 , 0.7137255 , 0.70980394, 0.6901961 , 0.6509804 ,\n","       0.65882355, 0.3882353 , 0.22745098, 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n","       0.28235295, 0.16078432, 0.13725491, 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        ], dtype=float32)"]},"metadata":{},"execution_count":145}],"source":["X_train_mlp[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n1IErvlmdhkF"},"outputs":[],"source":["num_classes=10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JyenYaffMvuR"},"outputs":[],"source":["Y_train_mlp= keras.utils.to_categorical(Y_train_mlp, num_classes)\n","Y_test_mlp= keras.utils.to_categorical(Y_test_mlp, num_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1698144568371,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"wgyLoqsIeiXt","outputId":"e06a3142-7347-4d94-d13b-63ee010bb5c7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n","       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n","       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"]},"metadata":{},"execution_count":148}],"source":["Y_train_mlp[:5, :]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XX-UjO0JeqjP"},"outputs":[],"source":["X_train_mlp, X_val_mlp, Y_train_mlp, Y_val_mlp= train_test_split(X_train_mlp, Y_train_mlp, test_size=0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1698144568371,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"gyCFdaO0fDTr","outputId":"dab8bf5b-9507-4681-8cc7-ad415a8ac863"},"outputs":[{"output_type":"stream","name":"stdout","text":["(48000, 784)\n"]}],"source":["print(X_train_mlp.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1698144568371,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"WmKdAPnvcdEZ","outputId":"9bb24b98-821a-4c79-a6bd-24b40f042c9a"},"outputs":[{"output_type":"stream","name":"stdout","text":["(12000, 784)\n"]}],"source":["print(X_val_mlp.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W6WJhpWVcgeB"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.optimizers import SGD\n","from keras.datasets import mnist\n","#from keras.utils import np_utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vg6LLVrXfPQK"},"outputs":[],"source":["batch_size= 256\n","num_epochs= 50"]},{"cell_type":"code","source":["import pandas as pd\n","# Create an empty 2D DataFrame to store Test accuracies and losses of each Ativation Function\n","df = pd.DataFrame()"],"metadata":{"id":"fxNpmWKjH78j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tkhM328MmZ_Q"},"source":["----------------------------------------------------------------------------------------"]},{"cell_type":"markdown","metadata":{"id":"-KsMI-I9OkBu"},"source":["## SIGMOID ACTIVATION FUNCTION"]},{"cell_type":"markdown","metadata":{"id":"TAoGD8h8Oqre"},"source":["----------------------------------------------------------------------------------------"]},{"cell_type":"markdown","metadata":{"id":"KtV2ZIe6L7fX"},"source":["# Shallow Single Layer Perceptron-  with Sigmoid AF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"thWz8zK1fe95"},"outputs":[],"source":["# Multilayer Perceptron Model\n","model1= Sequential()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ErLd54jafmUp"},"outputs":[],"source":["model1.add(Dense(input_dim=784, activation='sigmoid', units=625, kernel_initializer='normal'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"daD7Psl_fxBg"},"outputs":[],"source":["model1.add(Dense(input_dim=625, activation='softmax', units=10, kernel_initializer='normal'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1698144568371,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"ks4hlASvfzfX","outputId":"1408a2d0-92e0-4421-d5cb-c06e3ba9f8ff"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"]}],"source":["model1.compile(optimizer=SGD(lr=0.05), loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1698144568371,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"phNMLIIfgh-X","outputId":"cc415ffd-4b5d-44f7-fb83-f96db79f6fc0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_21 (Dense)            (None, 625)               490625    \n","                                                                 \n"," dense_22 (Dense)            (None, 10)                6260      \n","                                                                 \n","=================================================================\n","Total params: 496885 (1.90 MB)\n","Trainable params: 496885 (1.90 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model1.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43801,"status":"ok","timestamp":1698144612169,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"_CSI1iAXhwpf","outputId":"12b73b11-952f-4929-8da4-ffa33ca0a93e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","188/188 [==============================] - 1s 6ms/step - loss: 1.9880 - accuracy: 0.4886 - val_loss: 1.7261 - val_accuracy: 0.6572\n","Epoch 2/50\n","188/188 [==============================] - 1s 4ms/step - loss: 1.5357 - accuracy: 0.6694 - val_loss: 1.3919 - val_accuracy: 0.6860\n","Epoch 3/50\n","188/188 [==============================] - 1s 4ms/step - loss: 1.2735 - accuracy: 0.6987 - val_loss: 1.1946 - val_accuracy: 0.7063\n","Epoch 4/50\n","188/188 [==============================] - 1s 4ms/step - loss: 1.1142 - accuracy: 0.7159 - val_loss: 1.0681 - val_accuracy: 0.7216\n","Epoch 5/50\n","188/188 [==============================] - 1s 5ms/step - loss: 1.0096 - accuracy: 0.7246 - val_loss: 0.9825 - val_accuracy: 0.7273\n","Epoch 6/50\n","188/188 [==============================] - 1s 6ms/step - loss: 0.9361 - accuracy: 0.7322 - val_loss: 0.9204 - val_accuracy: 0.7348\n","Epoch 7/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.8821 - accuracy: 0.7388 - val_loss: 0.8747 - val_accuracy: 0.7366\n","Epoch 8/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.8406 - accuracy: 0.7433 - val_loss: 0.8368 - val_accuracy: 0.7429\n","Epoch 9/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.8074 - accuracy: 0.7474 - val_loss: 0.8066 - val_accuracy: 0.7471\n","Epoch 10/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.7803 - accuracy: 0.7518 - val_loss: 0.7823 - val_accuracy: 0.7483\n","Epoch 11/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.7577 - accuracy: 0.7562 - val_loss: 0.7623 - val_accuracy: 0.7502\n","Epoch 12/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.7385 - accuracy: 0.7590 - val_loss: 0.7431 - val_accuracy: 0.7563\n","Epoch 13/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.7217 - accuracy: 0.7622 - val_loss: 0.7295 - val_accuracy: 0.7586\n","Epoch 14/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.7072 - accuracy: 0.7645 - val_loss: 0.7138 - val_accuracy: 0.7644\n","Epoch 15/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6943 - accuracy: 0.7670 - val_loss: 0.7023 - val_accuracy: 0.7620\n","Epoch 16/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6827 - accuracy: 0.7697 - val_loss: 0.6916 - val_accuracy: 0.7677\n","Epoch 17/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6721 - accuracy: 0.7723 - val_loss: 0.6814 - val_accuracy: 0.7699\n","Epoch 18/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6626 - accuracy: 0.7750 - val_loss: 0.6714 - val_accuracy: 0.7730\n","Epoch 19/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.6537 - accuracy: 0.7774 - val_loss: 0.6634 - val_accuracy: 0.7744\n","Epoch 20/50\n","188/188 [==============================] - 1s 6ms/step - loss: 0.6456 - accuracy: 0.7783 - val_loss: 0.6562 - val_accuracy: 0.7757\n","Epoch 21/50\n","188/188 [==============================] - 1s 6ms/step - loss: 0.6381 - accuracy: 0.7815 - val_loss: 0.6476 - val_accuracy: 0.7799\n","Epoch 22/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6310 - accuracy: 0.7832 - val_loss: 0.6415 - val_accuracy: 0.7803\n","Epoch 23/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6244 - accuracy: 0.7859 - val_loss: 0.6348 - val_accuracy: 0.7823\n","Epoch 24/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6183 - accuracy: 0.7876 - val_loss: 0.6292 - val_accuracy: 0.7853\n","Epoch 25/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6124 - accuracy: 0.7893 - val_loss: 0.6249 - val_accuracy: 0.7862\n","Epoch 26/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6069 - accuracy: 0.7906 - val_loss: 0.6176 - val_accuracy: 0.7890\n","Epoch 27/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6015 - accuracy: 0.7928 - val_loss: 0.6137 - val_accuracy: 0.7898\n","Epoch 28/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5967 - accuracy: 0.7942 - val_loss: 0.6082 - val_accuracy: 0.7913\n","Epoch 29/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5920 - accuracy: 0.7958 - val_loss: 0.6036 - val_accuracy: 0.7943\n","Epoch 30/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5875 - accuracy: 0.7964 - val_loss: 0.5993 - val_accuracy: 0.7952\n","Epoch 31/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5833 - accuracy: 0.7975 - val_loss: 0.5955 - val_accuracy: 0.7964\n","Epoch 32/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5790 - accuracy: 0.7990 - val_loss: 0.5922 - val_accuracy: 0.7963\n","Epoch 33/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5752 - accuracy: 0.8006 - val_loss: 0.5870 - val_accuracy: 0.8001\n","Epoch 34/50\n","188/188 [==============================] - 1s 6ms/step - loss: 0.5714 - accuracy: 0.8014 - val_loss: 0.5830 - val_accuracy: 0.8010\n","Epoch 35/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.5678 - accuracy: 0.8028 - val_loss: 0.5811 - val_accuracy: 0.7997\n","Epoch 36/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.5644 - accuracy: 0.8042 - val_loss: 0.5762 - val_accuracy: 0.8031\n","Epoch 37/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5610 - accuracy: 0.8053 - val_loss: 0.5731 - val_accuracy: 0.8038\n","Epoch 38/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5577 - accuracy: 0.8070 - val_loss: 0.5704 - val_accuracy: 0.8058\n","Epoch 39/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5547 - accuracy: 0.8079 - val_loss: 0.5668 - val_accuracy: 0.8075\n","Epoch 40/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5518 - accuracy: 0.8083 - val_loss: 0.5648 - val_accuracy: 0.8062\n","Epoch 41/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5492 - accuracy: 0.8093 - val_loss: 0.5613 - val_accuracy: 0.8104\n","Epoch 42/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5463 - accuracy: 0.8109 - val_loss: 0.5587 - val_accuracy: 0.8097\n","Epoch 43/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5435 - accuracy: 0.8109 - val_loss: 0.5568 - val_accuracy: 0.8083\n","Epoch 44/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5411 - accuracy: 0.8113 - val_loss: 0.5541 - val_accuracy: 0.8097\n","Epoch 45/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5387 - accuracy: 0.8131 - val_loss: 0.5510 - val_accuracy: 0.8123\n","Epoch 46/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5361 - accuracy: 0.8135 - val_loss: 0.5488 - val_accuracy: 0.8138\n","Epoch 47/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5338 - accuracy: 0.8141 - val_loss: 0.5468 - val_accuracy: 0.8132\n","Epoch 48/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5316 - accuracy: 0.8151 - val_loss: 0.5452 - val_accuracy: 0.8148\n","Epoch 49/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.5294 - accuracy: 0.8163 - val_loss: 0.5419 - val_accuracy: 0.8159\n","Epoch 50/50\n","188/188 [==============================] - 1s 6ms/step - loss: 0.5272 - accuracy: 0.8168 - val_loss: 0.5403 - val_accuracy: 0.8156\n"]}],"source":["history= model1.fit(X_train_mlp, Y_train_mlp,\n","                   batch_size= batch_size,\n","                   epochs= num_epochs,\n","                   verbose=1,\n","                   validation_data=(X_val_mlp, Y_val_mlp))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":791,"status":"ok","timestamp":1698144612942,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"pAL3kVNQiAjG","outputId":"327f2a31-35c4-4638-f612-c6ebca329ac4"},"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 3ms/step - loss: 0.5514 - accuracy: 0.8044\n"]}],"source":["score= model1.evaluate(X_test_mlp, Y_test_mlp, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1698144612942,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"2hmFTJFcjl6D","outputId":"f48775cc-cb5f-4ffc-8ff0-10623b481931"},"outputs":[{"output_type":"stream","name":"stdout","text":["MLP Test Loss:  0.5514483451843262\n","MLP Test Accuracy:  0.8044000267982483\n"]}],"source":["print('MLP Test Loss: ', score[0])\n","print('MLP Test Accuracy: ', score[1])"]},{"cell_type":"code","source":["data=[]\n","column=[' Activation Function', ' Test Loss', '   Test Accuracy']\n","data.append(column)\n","data.append(['Sigmoid: Shallow MLP',score[0], score[1]] )\n","for row in data:\n","    print(row)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vTjOIXllIVMl","executionInfo":{"status":"ok","timestamp":1698144612943,"user_tz":-330,"elapsed":12,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"}},"outputId":"1a88932d-662a-4536-d95e-4dc39c262cdb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[' Activation Function', ' Test Loss', '   Test Accuracy']\n","['Sigmoid: Shallow MLP', 0.5514483451843262, 0.8044000267982483]\n"]}]},{"cell_type":"markdown","metadata":{"id":"vmCh3S52kDFs"},"source":["# Deep Multi Layer Perceptron - With Sigmoid"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T7Op_BkgnHWW"},"outputs":[],"source":["model1.add(Dense(input_dim=784, activation='sigmoid', units=625, kernel_initializer='normal'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9yuoBOjSkKop"},"outputs":[],"source":["model1.add(Dense(input_dim=625, activation='sigmoid', units=625, kernel_initializer='normal'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M-pzV-bXnHWX"},"outputs":[],"source":["model1.add(Dense(input_dim=625, activation='softmax', units=10, kernel_initializer='normal'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1698144612943,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"p4CsshBSnHWX","outputId":"f27f02ad-61f8-4cfe-9e50-84d9a17958ae"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"]}],"source":["model1.compile(optimizer=SGD(lr=0.05), loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":745,"status":"ok","timestamp":1698144613680,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"GK0XbivBnHWX","outputId":"f351ae88-9b8c-4316-9a8b-c1efce1227a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_21 (Dense)            (None, 625)               490625    \n","                                                                 \n"," dense_22 (Dense)            (None, 10)                6260      \n","                                                                 \n"," dense_23 (Dense)            (None, 625)               6875      \n","                                                                 \n"," dense_24 (Dense)            (None, 625)               391250    \n","                                                                 \n"," dense_25 (Dense)            (None, 10)                6260      \n","                                                                 \n","=================================================================\n","Total params: 901270 (3.44 MB)\n","Trainable params: 901270 (3.44 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model1.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":82735,"status":"ok","timestamp":1698144696410,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"6Kw6O6NpnHWY","outputId":"a51497a7-60cf-4baf-889f-f1aabdcfeafa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","188/188 [==============================] - 2s 6ms/step - loss: 2.3059 - accuracy: 0.1047 - val_loss: 2.3021 - val_accuracy: 0.1661\n","Epoch 2/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.3003 - accuracy: 0.1135 - val_loss: 2.3003 - val_accuracy: 0.1007\n","Epoch 3/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2982 - accuracy: 0.1161 - val_loss: 2.2976 - val_accuracy: 0.0961\n","Epoch 4/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2962 - accuracy: 0.1225 - val_loss: 2.2980 - val_accuracy: 0.1001\n","Epoch 5/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2940 - accuracy: 0.1380 - val_loss: 2.2929 - val_accuracy: 0.1029\n","Epoch 6/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2916 - accuracy: 0.1292 - val_loss: 2.2909 - val_accuracy: 0.1007\n","Epoch 7/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2897 - accuracy: 0.1452 - val_loss: 2.2910 - val_accuracy: 0.1563\n","Epoch 8/50\n","188/188 [==============================] - 1s 7ms/step - loss: 2.2876 - accuracy: 0.1471 - val_loss: 2.2863 - val_accuracy: 0.0983\n","Epoch 9/50\n","188/188 [==============================] - 1s 7ms/step - loss: 2.2852 - accuracy: 0.1477 - val_loss: 2.2831 - val_accuracy: 0.1486\n","Epoch 10/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2828 - accuracy: 0.1806 - val_loss: 2.2845 - val_accuracy: 0.1018\n","Epoch 11/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2807 - accuracy: 0.1962 - val_loss: 2.2796 - val_accuracy: 0.1290\n","Epoch 12/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2781 - accuracy: 0.1923 - val_loss: 2.2766 - val_accuracy: 0.3343\n","Epoch 13/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2759 - accuracy: 0.2292 - val_loss: 2.2744 - val_accuracy: 0.1231\n","Epoch 14/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2734 - accuracy: 0.2051 - val_loss: 2.2722 - val_accuracy: 0.0961\n","Epoch 15/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2704 - accuracy: 0.2275 - val_loss: 2.2695 - val_accuracy: 0.2403\n","Epoch 16/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2679 - accuracy: 0.2430 - val_loss: 2.2661 - val_accuracy: 0.2322\n","Epoch 17/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2651 - accuracy: 0.2670 - val_loss: 2.2662 - val_accuracy: 0.0988\n","Epoch 18/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2622 - accuracy: 0.2693 - val_loss: 2.2604 - val_accuracy: 0.1018\n","Epoch 19/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2589 - accuracy: 0.2858 - val_loss: 2.2571 - val_accuracy: 0.1902\n","Epoch 20/50\n","188/188 [==============================] - 1s 6ms/step - loss: 2.2559 - accuracy: 0.3127 - val_loss: 2.2547 - val_accuracy: 0.2362\n","Epoch 21/50\n","188/188 [==============================] - 1s 8ms/step - loss: 2.2526 - accuracy: 0.3345 - val_loss: 2.2518 - val_accuracy: 0.4757\n","Epoch 22/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2491 - accuracy: 0.3623 - val_loss: 2.2476 - val_accuracy: 0.5853\n","Epoch 23/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2457 - accuracy: 0.3730 - val_loss: 2.2441 - val_accuracy: 0.0977\n","Epoch 24/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2419 - accuracy: 0.3981 - val_loss: 2.2431 - val_accuracy: 0.1978\n","Epoch 25/50\n","188/188 [==============================] - 1s 6ms/step - loss: 2.2382 - accuracy: 0.4485 - val_loss: 2.2366 - val_accuracy: 0.1258\n","Epoch 26/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2338 - accuracy: 0.4272 - val_loss: 2.2342 - val_accuracy: 0.3327\n","Epoch 27/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2294 - accuracy: 0.4458 - val_loss: 2.2300 - val_accuracy: 0.1507\n","Epoch 28/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2251 - accuracy: 0.5040 - val_loss: 2.2242 - val_accuracy: 0.3532\n","Epoch 29/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2201 - accuracy: 0.5045 - val_loss: 2.2192 - val_accuracy: 0.2873\n","Epoch 30/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2149 - accuracy: 0.4874 - val_loss: 2.2117 - val_accuracy: 0.6272\n","Epoch 31/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.2097 - accuracy: 0.5501 - val_loss: 2.2089 - val_accuracy: 0.4232\n","Epoch 32/50\n","188/188 [==============================] - 1s 6ms/step - loss: 2.2040 - accuracy: 0.5602 - val_loss: 2.2009 - val_accuracy: 0.6380\n","Epoch 33/50\n","188/188 [==============================] - 1s 6ms/step - loss: 2.1979 - accuracy: 0.5846 - val_loss: 2.1963 - val_accuracy: 0.4173\n","Epoch 34/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.1916 - accuracy: 0.6113 - val_loss: 2.1884 - val_accuracy: 0.5604\n","Epoch 35/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.1850 - accuracy: 0.6305 - val_loss: 2.1820 - val_accuracy: 0.7217\n","Epoch 36/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.1777 - accuracy: 0.6374 - val_loss: 2.1750 - val_accuracy: 0.6795\n","Epoch 37/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.1700 - accuracy: 0.6386 - val_loss: 2.1682 - val_accuracy: 0.6863\n","Epoch 38/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.1620 - accuracy: 0.6751 - val_loss: 2.1607 - val_accuracy: 0.6219\n","Epoch 39/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.1533 - accuracy: 0.6763 - val_loss: 2.1489 - val_accuracy: 0.6949\n","Epoch 40/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.1440 - accuracy: 0.6936 - val_loss: 2.1417 - val_accuracy: 0.5930\n","Epoch 41/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.1342 - accuracy: 0.6946 - val_loss: 2.1309 - val_accuracy: 0.5840\n","Epoch 42/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.1239 - accuracy: 0.7063 - val_loss: 2.1199 - val_accuracy: 0.6946\n","Epoch 43/50\n","188/188 [==============================] - 1s 6ms/step - loss: 2.1123 - accuracy: 0.7126 - val_loss: 2.1085 - val_accuracy: 0.7340\n","Epoch 44/50\n","188/188 [==============================] - 1s 7ms/step - loss: 2.1002 - accuracy: 0.7106 - val_loss: 2.0969 - val_accuracy: 0.6386\n","Epoch 45/50\n","188/188 [==============================] - 1s 6ms/step - loss: 2.0870 - accuracy: 0.7216 - val_loss: 2.0806 - val_accuracy: 0.7564\n","Epoch 46/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.0726 - accuracy: 0.7189 - val_loss: 2.0687 - val_accuracy: 0.7632\n","Epoch 47/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.0578 - accuracy: 0.7342 - val_loss: 2.0519 - val_accuracy: 0.6948\n","Epoch 48/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.0415 - accuracy: 0.7234 - val_loss: 2.0372 - val_accuracy: 0.6316\n","Epoch 49/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.0241 - accuracy: 0.7258 - val_loss: 2.0169 - val_accuracy: 0.7079\n","Epoch 50/50\n","188/188 [==============================] - 1s 5ms/step - loss: 2.0052 - accuracy: 0.7320 - val_loss: 1.9967 - val_accuracy: 0.7403\n"]}],"source":["history= model1.fit(X_train_mlp, Y_train_mlp,\n","                   batch_size= batch_size,\n","                   epochs= num_epochs,\n","                   verbose=1,\n","                   validation_data=(X_val_mlp, Y_val_mlp))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":951,"status":"ok","timestamp":1698144697349,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"3ahP71_fnHWY","outputId":"44fb0a43-516f-4959-bd2b-150757d1f2cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 3ms/step - loss: 1.9977 - accuracy: 0.7406\n"]}],"source":["score= model1.evaluate(X_test_mlp, Y_test_mlp, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1698144697350,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"TBqfo7znnHWY","outputId":"455c3371-cd87-4a5e-c61e-1f70eeb5414a"},"outputs":[{"output_type":"stream","name":"stdout","text":["MLP Test Loss:  1.9976996183395386\n","MLP Test Accuracy:  0.7405999898910522\n"]}],"source":["print('MLP Test Loss: ', score[0])\n","print('MLP Test Accuracy: ', score[1])"]},{"cell_type":"code","source":["data.append(['Sigmoid: Deep MLP',score[0], score[1]] )\n","for row in data:\n","    print(row)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y_ftLiW8QXz-","executionInfo":{"status":"ok","timestamp":1698144697350,"user_tz":-330,"elapsed":9,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"}},"outputId":"f789fb40-4203-4cb9-8418-5af1dc218934"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[' Activation Function', ' Test Loss', '   Test Accuracy']\n","['Sigmoid: Shallow MLP', 0.5514483451843262, 0.8044000267982483]\n","['Sigmoid: Deep MLP', 1.9976996183395386, 0.7405999898910522]\n"]}]},{"cell_type":"markdown","metadata":{"id":"x7QgczctOVku"},"source":["----------------------------------------------------------------------------------------------------------------------------------------------------------------"]},{"cell_type":"markdown","metadata":{"id":"J_hsf8PuOyXl"},"source":["## RELU ACTIVATION FUNCTION"]},{"cell_type":"markdown","metadata":{"id":"xJJtWzWIOZlo"},"source":["----------------------------------------------------------------------------------------------"]},{"cell_type":"markdown","metadata":{"id":"ELm3pO20lnn5"},"source":["# Shallow Multi Layer Perceptron - With ReLU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YnfLRf5nOR12"},"outputs":[],"source":["model2=Sequential()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J_4dGKjfOR13"},"outputs":[],"source":["model2.add(Dense(input_dim=784, activation='relu', units=625, kernel_initializer='normal'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YHCqmUWTOR14"},"outputs":[],"source":["model2.add(Dense(input_dim=625, activation='softmax', units=10, kernel_initializer='normal'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1698144697827,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"bdL8809EOR14","outputId":"d3e9d456-9fe0-4e7b-e7f5-13d9e8625fdf"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"]}],"source":["model2.compile(optimizer=SGD(lr=0.05), loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1698144697827,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"uhEkaBM0OR14","outputId":"4a34d591-cfb7-441d-ee18-992479a2089c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_26 (Dense)            (None, 625)               490625    \n","                                                                 \n"," dense_27 (Dense)            (None, 10)                6260      \n","                                                                 \n","=================================================================\n","Total params: 496885 (1.90 MB)\n","Trainable params: 496885 (1.90 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model2.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":82457,"status":"ok","timestamp":1698144780277,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"VeBL4aAIOR14","outputId":"98a58b49-31e8-4a45-83ac-5c3664059522"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","188/188 [==============================] - 1s 5ms/step - loss: 1.3281 - accuracy: 0.6057 - val_loss: 0.9507 - val_accuracy: 0.7090\n","Epoch 2/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.8347 - accuracy: 0.7401 - val_loss: 0.7784 - val_accuracy: 0.7574\n","Epoch 3/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.7189 - accuracy: 0.7747 - val_loss: 0.6968 - val_accuracy: 0.7780\n","Epoch 4/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6580 - accuracy: 0.7920 - val_loss: 0.6492 - val_accuracy: 0.7948\n","Epoch 5/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6182 - accuracy: 0.8030 - val_loss: 0.6192 - val_accuracy: 0.8026\n","Epoch 6/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5893 - accuracy: 0.8115 - val_loss: 0.5922 - val_accuracy: 0.8083\n","Epoch 7/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5674 - accuracy: 0.8160 - val_loss: 0.5733 - val_accuracy: 0.8138\n","Epoch 8/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.5499 - accuracy: 0.8207 - val_loss: 0.5574 - val_accuracy: 0.8172\n","Epoch 9/50\n","188/188 [==============================] - 1s 6ms/step - loss: 0.5351 - accuracy: 0.8237 - val_loss: 0.5455 - val_accuracy: 0.8219\n","Epoch 10/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5230 - accuracy: 0.8281 - val_loss: 0.5339 - val_accuracy: 0.8243\n","Epoch 11/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5121 - accuracy: 0.8301 - val_loss: 0.5225 - val_accuracy: 0.8288\n","Epoch 12/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5033 - accuracy: 0.8328 - val_loss: 0.5136 - val_accuracy: 0.8307\n","Epoch 13/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4947 - accuracy: 0.8353 - val_loss: 0.5065 - val_accuracy: 0.8341\n","Epoch 14/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4870 - accuracy: 0.8371 - val_loss: 0.5064 - val_accuracy: 0.8278\n","Epoch 15/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4810 - accuracy: 0.8391 - val_loss: 0.4947 - val_accuracy: 0.8369\n","Epoch 16/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4750 - accuracy: 0.8412 - val_loss: 0.4889 - val_accuracy: 0.8384\n","Epoch 17/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4692 - accuracy: 0.8424 - val_loss: 0.4834 - val_accuracy: 0.8393\n","Epoch 18/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4642 - accuracy: 0.8444 - val_loss: 0.4804 - val_accuracy: 0.8404\n","Epoch 19/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4596 - accuracy: 0.8446 - val_loss: 0.4763 - val_accuracy: 0.8410\n","Epoch 20/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4551 - accuracy: 0.8462 - val_loss: 0.4702 - val_accuracy: 0.8426\n","Epoch 21/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4511 - accuracy: 0.8473 - val_loss: 0.4664 - val_accuracy: 0.8439\n","Epoch 22/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4473 - accuracy: 0.8489 - val_loss: 0.4647 - val_accuracy: 0.8434\n","Epoch 23/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.4438 - accuracy: 0.8496 - val_loss: 0.4617 - val_accuracy: 0.8451\n","Epoch 24/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.4400 - accuracy: 0.8501 - val_loss: 0.4624 - val_accuracy: 0.8422\n","Epoch 25/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4369 - accuracy: 0.8515 - val_loss: 0.4601 - val_accuracy: 0.8418\n","Epoch 26/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4340 - accuracy: 0.8519 - val_loss: 0.4520 - val_accuracy: 0.8472\n","Epoch 27/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4308 - accuracy: 0.8532 - val_loss: 0.4533 - val_accuracy: 0.8450\n","Epoch 28/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4281 - accuracy: 0.8537 - val_loss: 0.4480 - val_accuracy: 0.8487\n","Epoch 29/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4257 - accuracy: 0.8542 - val_loss: 0.4450 - val_accuracy: 0.8489\n","Epoch 30/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4227 - accuracy: 0.8549 - val_loss: 0.4419 - val_accuracy: 0.8490\n","Epoch 31/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4204 - accuracy: 0.8553 - val_loss: 0.4424 - val_accuracy: 0.8510\n","Epoch 32/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4180 - accuracy: 0.8570 - val_loss: 0.4378 - val_accuracy: 0.8523\n","Epoch 33/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4159 - accuracy: 0.8576 - val_loss: 0.4352 - val_accuracy: 0.8528\n","Epoch 34/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4134 - accuracy: 0.8582 - val_loss: 0.4344 - val_accuracy: 0.8524\n","Epoch 35/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4115 - accuracy: 0.8595 - val_loss: 0.4330 - val_accuracy: 0.8533\n","Epoch 36/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4092 - accuracy: 0.8595 - val_loss: 0.4300 - val_accuracy: 0.8537\n","Epoch 37/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4073 - accuracy: 0.8605 - val_loss: 0.4356 - val_accuracy: 0.8512\n","Epoch 38/50\n","188/188 [==============================] - 1s 7ms/step - loss: 0.4054 - accuracy: 0.8605 - val_loss: 0.4269 - val_accuracy: 0.8551\n","Epoch 39/50\n","188/188 [==============================] - 1s 7ms/step - loss: 0.4033 - accuracy: 0.8620 - val_loss: 0.4259 - val_accuracy: 0.8560\n","Epoch 40/50\n","188/188 [==============================] - 1s 7ms/step - loss: 0.4013 - accuracy: 0.8621 - val_loss: 0.4246 - val_accuracy: 0.8561\n","Epoch 41/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3995 - accuracy: 0.8627 - val_loss: 0.4328 - val_accuracy: 0.8482\n","Epoch 42/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3978 - accuracy: 0.8630 - val_loss: 0.4264 - val_accuracy: 0.8534\n","Epoch 43/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3961 - accuracy: 0.8650 - val_loss: 0.4222 - val_accuracy: 0.8548\n","Epoch 44/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3942 - accuracy: 0.8646 - val_loss: 0.4208 - val_accuracy: 0.8558\n","Epoch 45/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3925 - accuracy: 0.8656 - val_loss: 0.4190 - val_accuracy: 0.8572\n","Epoch 46/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3912 - accuracy: 0.8655 - val_loss: 0.4148 - val_accuracy: 0.8588\n","Epoch 47/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3895 - accuracy: 0.8662 - val_loss: 0.4134 - val_accuracy: 0.8586\n","Epoch 48/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3882 - accuracy: 0.8664 - val_loss: 0.4198 - val_accuracy: 0.8567\n","Epoch 49/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3870 - accuracy: 0.8667 - val_loss: 0.4143 - val_accuracy: 0.8571\n","Epoch 50/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3851 - accuracy: 0.8669 - val_loss: 0.4154 - val_accuracy: 0.8604\n"]}],"source":["history2= model2.fit(X_train_mlp, Y_train_mlp,\n","                   batch_size= batch_size,\n","                   epochs= num_epochs,\n","                   verbose=1,\n","                   validation_data=(X_val_mlp, Y_val_mlp))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1389,"status":"ok","timestamp":1698144781649,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"H4iYAs1UOR15","outputId":"ef09b553-a76b-4025-f1ae-b8594c368055"},"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 3ms/step - loss: 0.4317 - accuracy: 0.8501\n"]}],"source":["score= model2.evaluate(X_test_mlp, Y_test_mlp, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1698144781649,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"oaRR7ig1OR15","outputId":"4098ed99-5a70-4f41-976a-30c040f466ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["MLP Test Loss:  0.4316589832305908\n","MLP Test Accuracy:  0.8500999808311462\n"]}],"source":["print('MLP Test Loss: ', score[0])\n","print('MLP Test Accuracy: ', score[1])"]},{"cell_type":"code","source":["data.append(['Relu: Shallow MLP',score[0], score[1]] )\n","for row in data:\n","    print(row)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g8aB_LVhRC_l","executionInfo":{"status":"ok","timestamp":1698144781650,"user_tz":-330,"elapsed":14,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"}},"outputId":"f71e01c2-48f9-460f-9a87-1d7ddbbe9642"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[' Activation Function', ' Test Loss', '   Test Accuracy']\n","['Sigmoid: Shallow MLP', 0.5514483451843262, 0.8044000267982483]\n","['Sigmoid: Deep MLP', 1.9976996183395386, 0.7405999898910522]\n","['Relu: Shallow MLP', 0.4316589832305908, 0.8500999808311462]\n"]}]},{"cell_type":"markdown","metadata":{"id":"kSf9EXZ6s6FU"},"source":["# Deep Multi Layer Perceptron - With ReLU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Rhem_C7ql_X"},"outputs":[],"source":["model2=Sequential()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b-_fhlBoqf0l"},"outputs":[],"source":["model2.add(Dense(input_dim=784, activation='relu', units=625, kernel_initializer='normal'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DnfBcjXDqf0l"},"outputs":[],"source":["model2.add(Dense(input_dim=625, activation='relu', units=625, kernel_initializer='normal'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CZNOuT3vqf0l"},"outputs":[],"source":["model2.add(Dense(input_dim=625, activation='softmax', units=10, kernel_initializer='normal'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1698144781650,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"R4Jwi7Yhqf0l","outputId":"70b520dc-dbc6-408d-bf44-715cd324ca51"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"]}],"source":["model2.compile(optimizer=SGD(lr=0.05), loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1698144781650,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"VjKqQ21eqf0m","outputId":"4f98690b-dc33-47f3-82e5-00bd36b64964"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_28 (Dense)            (None, 625)               490625    \n","                                                                 \n"," dense_29 (Dense)            (None, 625)               391250    \n","                                                                 \n"," dense_30 (Dense)            (None, 10)                6260      \n","                                                                 \n","=================================================================\n","Total params: 888135 (3.39 MB)\n","Trainable params: 888135 (3.39 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model2.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46460,"status":"ok","timestamp":1698144828105,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"1GFms2J-l7xX","outputId":"014b660f-216a-4de9-f4cc-38c49ac1aede"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","188/188 [==============================] - 2s 6ms/step - loss: 1.2091 - accuracy: 0.6499 - val_loss: 0.8339 - val_accuracy: 0.7446\n","Epoch 2/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.7323 - accuracy: 0.7711 - val_loss: 0.6817 - val_accuracy: 0.7850\n","Epoch 3/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.6336 - accuracy: 0.7979 - val_loss: 0.6247 - val_accuracy: 0.8019\n","Epoch 4/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5821 - accuracy: 0.8106 - val_loss: 0.5799 - val_accuracy: 0.8142\n","Epoch 5/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5491 - accuracy: 0.8180 - val_loss: 0.5583 - val_accuracy: 0.8126\n","Epoch 6/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.5252 - accuracy: 0.8250 - val_loss: 0.5306 - val_accuracy: 0.8248\n","Epoch 7/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.5069 - accuracy: 0.8286 - val_loss: 0.5128 - val_accuracy: 0.8290\n","Epoch 8/50\n","188/188 [==============================] - 1s 7ms/step - loss: 0.4920 - accuracy: 0.8331 - val_loss: 0.5011 - val_accuracy: 0.8309\n","Epoch 9/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.4798 - accuracy: 0.8364 - val_loss: 0.4954 - val_accuracy: 0.8292\n","Epoch 10/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.4702 - accuracy: 0.8391 - val_loss: 0.4814 - val_accuracy: 0.8388\n","Epoch 11/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4619 - accuracy: 0.8421 - val_loss: 0.4869 - val_accuracy: 0.8323\n","Epoch 12/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4544 - accuracy: 0.8441 - val_loss: 0.4734 - val_accuracy: 0.8394\n","Epoch 13/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.4463 - accuracy: 0.8461 - val_loss: 0.4612 - val_accuracy: 0.8447\n","Epoch 14/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.4408 - accuracy: 0.8479 - val_loss: 0.4512 - val_accuracy: 0.8481\n","Epoch 15/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.4356 - accuracy: 0.8499 - val_loss: 0.4509 - val_accuracy: 0.8472\n","Epoch 16/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.4289 - accuracy: 0.8506 - val_loss: 0.4450 - val_accuracy: 0.8478\n","Epoch 17/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.4246 - accuracy: 0.8533 - val_loss: 0.4447 - val_accuracy: 0.8500\n","Epoch 18/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.4202 - accuracy: 0.8552 - val_loss: 0.4356 - val_accuracy: 0.8530\n","Epoch 19/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.4166 - accuracy: 0.8565 - val_loss: 0.4391 - val_accuracy: 0.8489\n","Epoch 20/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.4106 - accuracy: 0.8587 - val_loss: 0.4344 - val_accuracy: 0.8526\n","Epoch 21/50\n","188/188 [==============================] - 1s 7ms/step - loss: 0.4087 - accuracy: 0.8587 - val_loss: 0.4334 - val_accuracy: 0.8523\n","Epoch 22/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.4035 - accuracy: 0.8607 - val_loss: 0.4253 - val_accuracy: 0.8558\n","Epoch 23/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.4018 - accuracy: 0.8619 - val_loss: 0.4201 - val_accuracy: 0.8569\n","Epoch 24/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3977 - accuracy: 0.8627 - val_loss: 0.4356 - val_accuracy: 0.8458\n","Epoch 25/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3942 - accuracy: 0.8631 - val_loss: 0.4148 - val_accuracy: 0.8569\n","Epoch 26/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3917 - accuracy: 0.8640 - val_loss: 0.4541 - val_accuracy: 0.8371\n","Epoch 27/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3887 - accuracy: 0.8656 - val_loss: 0.4146 - val_accuracy: 0.8582\n","Epoch 28/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3858 - accuracy: 0.8663 - val_loss: 0.4177 - val_accuracy: 0.8553\n","Epoch 29/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3829 - accuracy: 0.8676 - val_loss: 0.4051 - val_accuracy: 0.8596\n","Epoch 30/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3814 - accuracy: 0.8682 - val_loss: 0.4042 - val_accuracy: 0.8600\n","Epoch 31/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3791 - accuracy: 0.8674 - val_loss: 0.4227 - val_accuracy: 0.8539\n","Epoch 32/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3756 - accuracy: 0.8698 - val_loss: 0.4032 - val_accuracy: 0.8608\n","Epoch 33/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3734 - accuracy: 0.8708 - val_loss: 0.3986 - val_accuracy: 0.8632\n","Epoch 34/50\n","188/188 [==============================] - 1s 6ms/step - loss: 0.3709 - accuracy: 0.8721 - val_loss: 0.3980 - val_accuracy: 0.8627\n","Epoch 35/50\n","188/188 [==============================] - 1s 7ms/step - loss: 0.3700 - accuracy: 0.8711 - val_loss: 0.4004 - val_accuracy: 0.8627\n","Epoch 36/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3667 - accuracy: 0.8727 - val_loss: 0.3973 - val_accuracy: 0.8628\n","Epoch 37/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3643 - accuracy: 0.8731 - val_loss: 0.3957 - val_accuracy: 0.8626\n","Epoch 38/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3619 - accuracy: 0.8748 - val_loss: 0.3923 - val_accuracy: 0.8633\n","Epoch 39/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3609 - accuracy: 0.8754 - val_loss: 0.3876 - val_accuracy: 0.8661\n","Epoch 40/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3583 - accuracy: 0.8758 - val_loss: 0.3907 - val_accuracy: 0.8633\n","Epoch 41/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3579 - accuracy: 0.8755 - val_loss: 0.3857 - val_accuracy: 0.8660\n","Epoch 42/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3543 - accuracy: 0.8772 - val_loss: 0.3845 - val_accuracy: 0.8660\n","Epoch 43/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3522 - accuracy: 0.8786 - val_loss: 0.3830 - val_accuracy: 0.8667\n","Epoch 44/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3510 - accuracy: 0.8779 - val_loss: 0.3903 - val_accuracy: 0.8658\n","Epoch 45/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3484 - accuracy: 0.8794 - val_loss: 0.3809 - val_accuracy: 0.8667\n","Epoch 46/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3466 - accuracy: 0.8789 - val_loss: 0.3959 - val_accuracy: 0.8595\n","Epoch 47/50\n","188/188 [==============================] - 1s 6ms/step - loss: 0.3448 - accuracy: 0.8807 - val_loss: 0.3825 - val_accuracy: 0.8658\n","Epoch 48/50\n","188/188 [==============================] - 1s 7ms/step - loss: 0.3439 - accuracy: 0.8809 - val_loss: 0.3778 - val_accuracy: 0.8673\n","Epoch 49/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3425 - accuracy: 0.8804 - val_loss: 0.3834 - val_accuracy: 0.8687\n","Epoch 50/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3403 - accuracy: 0.8811 - val_loss: 0.3827 - val_accuracy: 0.8667\n"]}],"source":["history2= model2.fit(X_train_mlp, Y_train_mlp,\n","                   batch_size= batch_size,\n","                   epochs= num_epochs,\n","                   verbose=1,\n","                   validation_data=(X_val_mlp, Y_val_mlp))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1385,"status":"ok","timestamp":1698144829462,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"qp9ewa6atoAm","outputId":"c4e1df32-8939-4a78-bd66-5505760bc581"},"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 3ms/step - loss: 0.4011 - accuracy: 0.8574\n"]}],"source":["score= model2.evaluate(X_test_mlp, Y_test_mlp, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1698144829463,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"id":"jnU1YmdjtoAm","outputId":"fb568668-e4bc-458b-d0d6-483e748efb10"},"outputs":[{"output_type":"stream","name":"stdout","text":["MLP Test Loss:  0.40113499760627747\n","MLP Test Accuracy:  0.8574000000953674\n"]}],"source":["print('MLP Test Loss: ', score[0])\n","print('MLP Test Accuracy: ', score[1])"]},{"cell_type":"code","source":["data.append(['Relu: Deep MLP',score[0], score[1]] )\n","for row in data:\n","    print(row)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W-huAMpTRZM8","executionInfo":{"status":"ok","timestamp":1698144829463,"user_tz":-330,"elapsed":5,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"}},"outputId":"5b8c5f6c-26b3-41ae-c98b-c76dd100134b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[' Activation Function', ' Test Loss', '   Test Accuracy']\n","['Sigmoid: Shallow MLP', 0.5514483451843262, 0.8044000267982483]\n","['Sigmoid: Deep MLP', 1.9976996183395386, 0.7405999898910522]\n","['Relu: Shallow MLP', 0.4316589832305908, 0.8500999808311462]\n","['Relu: Deep MLP', 0.40113499760627747, 0.8574000000953674]\n"]}]},{"cell_type":"markdown","source":["----------------------------------------------------------------------------------------------"],"metadata":{"id":"Y8Es_xdfWH0H"}},{"cell_type":"markdown","source":["#LEAKY RELU ACTIVATION FUNCTION"],"metadata":{"id":"NATqigBXWK11"}},{"cell_type":"markdown","source":["------------------------------------------------------------------------------------"],"metadata":{"id":"7OVdpJg6WUxx"}},{"cell_type":"markdown","metadata":{"id":"h_0h0acCWd62"},"source":["# Shallow Multi Layer Perceptron - With Leaky ReLU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xT-rYE3YWd63"},"outputs":[],"source":["model3=Sequential()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ieyeiqt0Wd63"},"outputs":[],"source":["model3.add(Dense(input_dim=784, activation='leaky_relu', units=625, kernel_initializer='normal'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GfazSj2KWd64"},"outputs":[],"source":["model3.add(Dense(input_dim=625, activation='softmax', units=10, kernel_initializer='normal'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1698144830420,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"outputId":"91ba12b9-82b7-4fe9-8696-5da1cfc78860","id":"CqW23V5NWd64"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"]}],"source":["model3.compile(optimizer=SGD(lr=0.05), loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1698144830420,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"outputId":"8743ae72-cedc-4428-8023-5c010df04ca1","id":"EiQQFj0CWd64"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_9\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_31 (Dense)            (None, 625)               490625    \n","                                                                 \n"," dense_32 (Dense)            (None, 10)                6260      \n","                                                                 \n","=================================================================\n","Total params: 496885 (1.90 MB)\n","Trainable params: 496885 (1.90 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model3.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":82175,"status":"ok","timestamp":1698144912588,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"outputId":"48336196-40f4-47eb-db73-6dbaf43cf54e","id":"o93NVaOTWd65"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3387 - accuracy: 0.8824 - val_loss: 0.3787 - val_accuracy: 0.8682\n","Epoch 2/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3367 - accuracy: 0.8827 - val_loss: 0.4029 - val_accuracy: 0.8571\n","Epoch 3/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3349 - accuracy: 0.8835 - val_loss: 0.3958 - val_accuracy: 0.8608\n","Epoch 4/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3335 - accuracy: 0.8841 - val_loss: 0.3733 - val_accuracy: 0.8704\n","Epoch 5/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3327 - accuracy: 0.8845 - val_loss: 0.3680 - val_accuracy: 0.8699\n","Epoch 6/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3317 - accuracy: 0.8825 - val_loss: 0.3733 - val_accuracy: 0.8707\n","Epoch 7/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3293 - accuracy: 0.8851 - val_loss: 0.3680 - val_accuracy: 0.8722\n","Epoch 8/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3274 - accuracy: 0.8855 - val_loss: 0.3796 - val_accuracy: 0.8696\n","Epoch 9/50\n","188/188 [==============================] - 1s 7ms/step - loss: 0.3255 - accuracy: 0.8864 - val_loss: 0.3759 - val_accuracy: 0.8696\n","Epoch 10/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3249 - accuracy: 0.8860 - val_loss: 0.3700 - val_accuracy: 0.8715\n","Epoch 11/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3245 - accuracy: 0.8861 - val_loss: 0.3707 - val_accuracy: 0.8693\n","Epoch 12/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3224 - accuracy: 0.8863 - val_loss: 0.3674 - val_accuracy: 0.8710\n","Epoch 13/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3197 - accuracy: 0.8885 - val_loss: 0.3711 - val_accuracy: 0.8707\n","Epoch 14/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3183 - accuracy: 0.8892 - val_loss: 0.3635 - val_accuracy: 0.8738\n","Epoch 15/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3182 - accuracy: 0.8879 - val_loss: 0.3670 - val_accuracy: 0.8737\n","Epoch 16/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3180 - accuracy: 0.8888 - val_loss: 0.3588 - val_accuracy: 0.8741\n","Epoch 17/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3153 - accuracy: 0.8888 - val_loss: 0.3666 - val_accuracy: 0.8731\n","Epoch 18/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3144 - accuracy: 0.8901 - val_loss: 0.3566 - val_accuracy: 0.8753\n","Epoch 19/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3119 - accuracy: 0.8904 - val_loss: 0.3676 - val_accuracy: 0.8691\n","Epoch 20/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3116 - accuracy: 0.8912 - val_loss: 0.3563 - val_accuracy: 0.8738\n","Epoch 21/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3110 - accuracy: 0.8908 - val_loss: 0.3588 - val_accuracy: 0.8740\n","Epoch 22/50\n","188/188 [==============================] - 1s 6ms/step - loss: 0.3090 - accuracy: 0.8921 - val_loss: 0.3689 - val_accuracy: 0.8713\n","Epoch 23/50\n","188/188 [==============================] - 1s 6ms/step - loss: 0.3082 - accuracy: 0.8925 - val_loss: 0.3560 - val_accuracy: 0.8737\n","Epoch 24/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.3063 - accuracy: 0.8931 - val_loss: 0.3664 - val_accuracy: 0.8727\n","Epoch 25/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3048 - accuracy: 0.8928 - val_loss: 0.3562 - val_accuracy: 0.8719\n","Epoch 26/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3042 - accuracy: 0.8931 - val_loss: 0.3634 - val_accuracy: 0.8698\n","Epoch 27/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3031 - accuracy: 0.8930 - val_loss: 0.3523 - val_accuracy: 0.8758\n","Epoch 28/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3024 - accuracy: 0.8940 - val_loss: 0.3613 - val_accuracy: 0.8743\n","Epoch 29/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.3008 - accuracy: 0.8930 - val_loss: 0.3589 - val_accuracy: 0.8744\n","Epoch 30/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.2992 - accuracy: 0.8949 - val_loss: 0.3497 - val_accuracy: 0.8767\n","Epoch 31/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2972 - accuracy: 0.8956 - val_loss: 0.3535 - val_accuracy: 0.8730\n","Epoch 32/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2970 - accuracy: 0.8955 - val_loss: 0.3512 - val_accuracy: 0.8755\n","Epoch 33/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.2958 - accuracy: 0.8963 - val_loss: 0.3653 - val_accuracy: 0.8670\n","Epoch 34/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.2952 - accuracy: 0.8965 - val_loss: 0.3473 - val_accuracy: 0.8764\n","Epoch 35/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2937 - accuracy: 0.8967 - val_loss: 0.3470 - val_accuracy: 0.8762\n","Epoch 36/50\n","188/188 [==============================] - 1s 6ms/step - loss: 0.2917 - accuracy: 0.8976 - val_loss: 0.3470 - val_accuracy: 0.8769\n","Epoch 37/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2915 - accuracy: 0.8972 - val_loss: 0.3593 - val_accuracy: 0.8725\n","Epoch 38/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.2904 - accuracy: 0.8981 - val_loss: 0.3448 - val_accuracy: 0.8769\n","Epoch 39/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.2898 - accuracy: 0.8982 - val_loss: 0.3450 - val_accuracy: 0.8785\n","Epoch 40/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2871 - accuracy: 0.8998 - val_loss: 0.3456 - val_accuracy: 0.8767\n","Epoch 41/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.2879 - accuracy: 0.8983 - val_loss: 0.3544 - val_accuracy: 0.8746\n","Epoch 42/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.2857 - accuracy: 0.8996 - val_loss: 0.3470 - val_accuracy: 0.8763\n","Epoch 43/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.2857 - accuracy: 0.9001 - val_loss: 0.3512 - val_accuracy: 0.8753\n","Epoch 44/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2841 - accuracy: 0.9011 - val_loss: 0.3411 - val_accuracy: 0.8777\n","Epoch 45/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.2818 - accuracy: 0.9014 - val_loss: 0.3468 - val_accuracy: 0.8782\n","Epoch 46/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2812 - accuracy: 0.9018 - val_loss: 0.3470 - val_accuracy: 0.8756\n","Epoch 47/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2800 - accuracy: 0.9020 - val_loss: 0.3496 - val_accuracy: 0.8780\n","Epoch 48/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.2785 - accuracy: 0.9029 - val_loss: 0.3534 - val_accuracy: 0.8733\n","Epoch 49/50\n","188/188 [==============================] - 1s 6ms/step - loss: 0.2771 - accuracy: 0.9029 - val_loss: 0.3480 - val_accuracy: 0.8767\n","Epoch 50/50\n","188/188 [==============================] - 1s 6ms/step - loss: 0.2764 - accuracy: 0.9039 - val_loss: 0.3488 - val_accuracy: 0.8773\n"]}],"source":["history3= model2.fit(X_train_mlp, Y_train_mlp,\n","                   batch_size= batch_size,\n","                   epochs= num_epochs,\n","                   verbose=1,\n","                   validation_data=(X_val_mlp, Y_val_mlp))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":998,"status":"ok","timestamp":1698144913581,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"outputId":"1a956698-3079-4dbd-fe88-51e780866b4b","id":"ozobZVPZWd65"},"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 3ms/step - loss: 2.4849 - accuracy: 0.0175\n"]}],"source":["score= model3.evaluate(X_test_mlp, Y_test_mlp, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1698144913582,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"outputId":"cb456c78-3958-4252-f749-c2536b89eace","id":"WpaCuVdzWd65"},"outputs":[{"output_type":"stream","name":"stdout","text":["MLP Test Loss:  2.48492169380188\n","MLP Test Accuracy:  0.017500000074505806\n"]}],"source":["print('MLP Test Loss: ', score[0])\n","print('MLP Test Accuracy: ', score[1])"]},{"cell_type":"code","source":["data.append(['Leaky Relu: Shallow MLP',score[0], score[1]] )\n","for row in data:\n","    print(row)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0naVdak1R_mn","executionInfo":{"status":"ok","timestamp":1698144913582,"user_tz":-330,"elapsed":12,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"}},"outputId":"a6c25f3a-da1d-440d-d302-8f4d1c59030f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[' Activation Function', ' Test Loss', '   Test Accuracy']\n","['Sigmoid: Shallow MLP', 0.5514483451843262, 0.8044000267982483]\n","['Sigmoid: Deep MLP', 1.9976996183395386, 0.7405999898910522]\n","['Relu: Shallow MLP', 0.4316589832305908, 0.8500999808311462]\n","['Relu: Deep MLP', 0.40113499760627747, 0.8574000000953674]\n","['Leaky Relu: Shallow MLP', 2.48492169380188, 0.017500000074505806]\n"]}]},{"cell_type":"markdown","metadata":{"id":"q4wY_voFWd65"},"source":["# Deep Multi Layer Perceptron - With Leaky ReLU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x1bfzKgUWd65"},"outputs":[],"source":["model3=Sequential()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cqsBdFnzWd65"},"outputs":[],"source":["model3.add(Dense(input_dim=784, activation='leaky_relu', units=625, kernel_initializer='normal'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xDkyghZFWd65"},"outputs":[],"source":["model3.add(Dense(input_dim=625, activation='leaky_relu', units=625, kernel_initializer='normal'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6gQ_VU1qWd66"},"outputs":[],"source":["model3.add(Dense(input_dim=625, activation='softmax', units=10, kernel_initializer='normal'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1698144913583,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"outputId":"e35c7ae9-e7aa-435c-8906-1fcf9db53551","id":"hA1zl3UcWd66"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"]}],"source":["model3.compile(optimizer=SGD(lr=0.05), loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1698144913583,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"outputId":"e3e0c575-9a2b-4c02-cc7a-ab875362a71b","id":"0aMeDYftWd66"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_10\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_33 (Dense)            (None, 625)               490625    \n","                                                                 \n"," dense_34 (Dense)            (None, 625)               391250    \n","                                                                 \n"," dense_35 (Dense)            (None, 10)                6260      \n","                                                                 \n","=================================================================\n","Total params: 888135 (3.39 MB)\n","Trainable params: 888135 (3.39 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model3.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45908,"status":"ok","timestamp":1698144959486,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"outputId":"ae926d30-e6b2-4869-e8c0-76f7259f948a","id":"4ZwGGtcdWd66"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2767 - accuracy: 0.9025 - val_loss: 0.3401 - val_accuracy: 0.8788\n","Epoch 2/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2748 - accuracy: 0.9036 - val_loss: 0.3411 - val_accuracy: 0.8788\n","Epoch 3/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2736 - accuracy: 0.9040 - val_loss: 0.3420 - val_accuracy: 0.8786\n","Epoch 4/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2734 - accuracy: 0.9044 - val_loss: 0.3416 - val_accuracy: 0.8797\n","Epoch 5/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2729 - accuracy: 0.9037 - val_loss: 0.3349 - val_accuracy: 0.8800\n","Epoch 6/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2725 - accuracy: 0.9045 - val_loss: 0.3407 - val_accuracy: 0.8784\n","Epoch 7/50\n","188/188 [==============================] - 1s 7ms/step - loss: 0.2698 - accuracy: 0.9055 - val_loss: 0.3433 - val_accuracy: 0.8789\n","Epoch 8/50\n","188/188 [==============================] - 1s 6ms/step - loss: 0.2695 - accuracy: 0.9064 - val_loss: 0.3366 - val_accuracy: 0.8792\n","Epoch 9/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2675 - accuracy: 0.9070 - val_loss: 0.3481 - val_accuracy: 0.8750\n","Epoch 10/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2685 - accuracy: 0.9052 - val_loss: 0.3682 - val_accuracy: 0.8648\n","Epoch 11/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.2666 - accuracy: 0.9061 - val_loss: 0.3343 - val_accuracy: 0.8817\n","Epoch 12/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2661 - accuracy: 0.9070 - val_loss: 0.3466 - val_accuracy: 0.8754\n","Epoch 13/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.2658 - accuracy: 0.9064 - val_loss: 0.3315 - val_accuracy: 0.8816\n","Epoch 14/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2637 - accuracy: 0.9081 - val_loss: 0.3486 - val_accuracy: 0.8776\n","Epoch 15/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2640 - accuracy: 0.9074 - val_loss: 0.3495 - val_accuracy: 0.8768\n","Epoch 16/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2617 - accuracy: 0.9079 - val_loss: 0.3334 - val_accuracy: 0.8809\n","Epoch 17/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2605 - accuracy: 0.9090 - val_loss: 0.3458 - val_accuracy: 0.8742\n","Epoch 18/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.2598 - accuracy: 0.9084 - val_loss: 0.3498 - val_accuracy: 0.8767\n","Epoch 19/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.2589 - accuracy: 0.9087 - val_loss: 0.3721 - val_accuracy: 0.8731\n","Epoch 20/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2577 - accuracy: 0.9092 - val_loss: 0.3486 - val_accuracy: 0.8737\n","Epoch 21/50\n","188/188 [==============================] - 1s 6ms/step - loss: 0.2573 - accuracy: 0.9099 - val_loss: 0.3365 - val_accuracy: 0.8817\n","Epoch 22/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2555 - accuracy: 0.9112 - val_loss: 0.3285 - val_accuracy: 0.8813\n","Epoch 23/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.2562 - accuracy: 0.9105 - val_loss: 0.3315 - val_accuracy: 0.8815\n","Epoch 24/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2544 - accuracy: 0.9099 - val_loss: 0.3300 - val_accuracy: 0.8827\n","Epoch 25/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2542 - accuracy: 0.9111 - val_loss: 0.3322 - val_accuracy: 0.8823\n","Epoch 26/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.2518 - accuracy: 0.9115 - val_loss: 0.3284 - val_accuracy: 0.8817\n","Epoch 27/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2523 - accuracy: 0.9114 - val_loss: 0.3334 - val_accuracy: 0.8783\n","Epoch 28/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2494 - accuracy: 0.9129 - val_loss: 0.3266 - val_accuracy: 0.8828\n","Epoch 29/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2506 - accuracy: 0.9121 - val_loss: 0.3453 - val_accuracy: 0.8793\n","Epoch 30/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2494 - accuracy: 0.9127 - val_loss: 0.3375 - val_accuracy: 0.8808\n","Epoch 31/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2465 - accuracy: 0.9136 - val_loss: 0.3310 - val_accuracy: 0.8802\n","Epoch 32/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2465 - accuracy: 0.9143 - val_loss: 0.3241 - val_accuracy: 0.8822\n","Epoch 33/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.2458 - accuracy: 0.9141 - val_loss: 0.3332 - val_accuracy: 0.8792\n","Epoch 34/50\n","188/188 [==============================] - 1s 6ms/step - loss: 0.2456 - accuracy: 0.9132 - val_loss: 0.3624 - val_accuracy: 0.8742\n","Epoch 35/50\n","188/188 [==============================] - 1s 6ms/step - loss: 0.2453 - accuracy: 0.9144 - val_loss: 0.3306 - val_accuracy: 0.8837\n","Epoch 36/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.2435 - accuracy: 0.9149 - val_loss: 0.3260 - val_accuracy: 0.8812\n","Epoch 37/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.2426 - accuracy: 0.9151 - val_loss: 0.3288 - val_accuracy: 0.8826\n","Epoch 38/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2422 - accuracy: 0.9159 - val_loss: 0.3286 - val_accuracy: 0.8810\n","Epoch 39/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2409 - accuracy: 0.9168 - val_loss: 0.3261 - val_accuracy: 0.8843\n","Epoch 40/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2418 - accuracy: 0.9157 - val_loss: 0.3329 - val_accuracy: 0.8792\n","Epoch 41/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.2388 - accuracy: 0.9168 - val_loss: 0.3376 - val_accuracy: 0.8773\n","Epoch 42/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2392 - accuracy: 0.9160 - val_loss: 0.3314 - val_accuracy: 0.8794\n","Epoch 43/50\n","188/188 [==============================] - 1s 4ms/step - loss: 0.2369 - accuracy: 0.9168 - val_loss: 0.3264 - val_accuracy: 0.8848\n","Epoch 44/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2372 - accuracy: 0.9171 - val_loss: 0.3279 - val_accuracy: 0.8818\n","Epoch 45/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2361 - accuracy: 0.9180 - val_loss: 0.3239 - val_accuracy: 0.8837\n","Epoch 46/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2349 - accuracy: 0.9181 - val_loss: 0.3329 - val_accuracy: 0.8799\n","Epoch 47/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2348 - accuracy: 0.9180 - val_loss: 0.3219 - val_accuracy: 0.8842\n","Epoch 48/50\n","188/188 [==============================] - 1s 6ms/step - loss: 0.2338 - accuracy: 0.9179 - val_loss: 0.3459 - val_accuracy: 0.8756\n","Epoch 49/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2337 - accuracy: 0.9185 - val_loss: 0.3236 - val_accuracy: 0.8821\n","Epoch 50/50\n","188/188 [==============================] - 1s 5ms/step - loss: 0.2334 - accuracy: 0.9182 - val_loss: 0.3373 - val_accuracy: 0.8777\n"]}],"source":["history3= model2.fit(X_train_mlp, Y_train_mlp,\n","                   batch_size= batch_size,\n","                   epochs= num_epochs,\n","                   verbose=1,\n","                   validation_data=(X_val_mlp, Y_val_mlp))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1302,"status":"ok","timestamp":1698144960777,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"outputId":"44dfbf12-4d14-449b-edb2-5847246490b7","id":"hEqvbiulWd66"},"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 2ms/step - loss: 2.5248 - accuracy: 0.0139\n"]}],"source":["score= model3.evaluate(X_test_mlp, Y_test_mlp, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1698144960777,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"},"user_tz":-330},"outputId":"61ef2341-4624-4d1f-a272-e3dfc55cd4e7","id":"ziyCXtcSWd67"},"outputs":[{"output_type":"stream","name":"stdout","text":["MLP Test Loss:  2.524839162826538\n","MLP Test Accuracy:  0.013899999670684338\n"]}],"source":["print('MLP Test Loss: ', score[0])\n","print('MLP Test Accuracy: ', score[1])"]},{"cell_type":"code","source":["data.append(['Leaky Relu: Deep MLP',score[0], score[1]] )\n","for row in data:\n","    print(row)"],"metadata":{"id":"vqSUqac9YGH8","executionInfo":{"status":"ok","timestamp":1698144960777,"user_tz":-330,"elapsed":3,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c0ead4a1-55e7-4cc6-e70a-077bbf900820"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[' Activation Function', ' Test Loss', '   Test Accuracy']\n","['Sigmoid: Shallow MLP', 0.5514483451843262, 0.8044000267982483]\n","['Sigmoid: Deep MLP', 1.9976996183395386, 0.7405999898910522]\n","['Relu: Shallow MLP', 0.4316589832305908, 0.8500999808311462]\n","['Relu: Deep MLP', 0.40113499760627747, 0.8574000000953674]\n","['Leaky Relu: Shallow MLP', 2.48492169380188, 0.017500000074505806]\n","['Leaky Relu: Deep MLP', 2.524839162826538, 0.013899999670684338]\n"]}]},{"cell_type":"markdown","source":["# FINAL TABLE FOR COMPARISION OF LOSS AND ACCURACIES OF ALL ACTIVATION FUNCTIONS: Sigmoid, Relu, Leaky Relu"],"metadata":{"id":"XJS8-wTpVcKM"}},{"cell_type":"code","source":["for row in data:\n","    print(row)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lSmHtdpVVkb6","executionInfo":{"status":"ok","timestamp":1698145137220,"user_tz":-330,"elapsed":492,"user":{"displayName":"Archisha Sinha","userId":"04837774794656308874"}},"outputId":"d38aad57-8efc-4630-83df-8a69169219f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[' Activation Function', ' Test Loss', '   Test Accuracy']\n","['Sigmoid: Shallow MLP', 0.5514483451843262, 0.8044000267982483]\n","['Sigmoid: Deep MLP', 1.9976996183395386, 0.7405999898910522]\n","['Relu: Shallow MLP', 0.4316589832305908, 0.8500999808311462]\n","['Relu: Deep MLP', 0.40113499760627747, 0.8574000000953674]\n","['Leaky Relu: Shallow MLP', 2.48492169380188, 0.017500000074505806]\n","['Leaky Relu: Deep MLP', 2.524839162826538, 0.013899999670684338]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"IzsRY-uoVmx2"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM4PDNKwhrnRWFp1vNJEFrL"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}